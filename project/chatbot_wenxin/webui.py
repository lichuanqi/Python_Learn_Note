import gradio as gr
import random
import time

from util import wenxin_to_chatbot, chatbot_to_wenxin
from api import ACCESS_TIME, ACCESS_TOKEN
from api import update_access_token, chat_by_token


def predict_base(message, chatbot, history:list=[]):
    """æ–‡æœ¬ç”Ÿæˆä¸»å‡½æ•°, ä¸»è¦ç”¨æˆ·è°ƒè¯•æ¯æ¬¡éƒ½è¿”å›å›ºå®šçš„å­—ç¬¦ä¸²
    
    Params
        message: è¾“å…¥
        history: 

    Return
        response: å¯¹åº”äºæ‰€æœ‰ç”¨æˆ·å’Œæœºå™¨äººå“åº”çš„å­—ç¬¦ä¸²å…ƒç»„åˆ—è¡¨ã€‚
                  è¿™å°†åœ¨ Gradio æ¼”ç¤ºä¸­å‘ˆç°ä¸ºè¾“å‡ºã€‚
        history: æ‰€æœ‰ç”¨æˆ·å’Œæœºå™¨äººå“åº”çš„ä»¤ç‰Œè¡¨ç¤ºã€‚
                 åœ¨æœ‰çŠ¶æ€çš„ Gradio æ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨å‡½æ•°ç»“æŸæ—¶è¿”å›æ›´æ–°çš„çŠ¶æ€ã€‚
    """
    history.append({"role": "user", "content": message})
    response = "ä½ å¥½ä½ å¥½"
    history.append({"role": "assistant", "content": response})
    
    messages = [(history[i]["content"], history[i+1]["content"]) for i in range(0, len(history)-1, 2)]

    return "", messages, history


def predict_wenxin(message, chatbot):
    """æ–‡æœ¬ç”Ÿæˆä¸»å‡½æ•°, è°ƒç”¨æ–‡å¿ƒä¸€è¨€æ¥å£"""
    access_time, access_token = update_access_token(ACCESS_TIME, ACCESS_TOKEN)

    history = chatbot_to_wenxin(chatbot)
    history.append({"role": "user","content": message})
    reponse = chat_by_token(access_token, history, stream=False)

    # å­—ç¬¦ä¸²ç»“æœ
    result = reponse["result"]
    # tokensæ•°
    prompt_tokens, completion_tokens = reponse["usage"]["prompt_tokens"], reponse["usage"]["completion_tokens"]

    history.append({"role": "assistant","content": result})
    messages = wenxin_to_chatbot(history)

    return "", messages


def on_clear():
    print('å·²æ¸…ç©ºå†å²æ¶ˆæ¯')
    return [], None


with gr.Blocks(
    title="LLM",
    theme=gr.themes.Soft()
) as demo:
    gr.Markdown(
        """
        ## ğŸš€LLMåŠ©æ‰‹
        ä½¿ç”¨æ–‡å¿ƒä¸€è¨€å•†ç”¨APIå®ç°çš„å¤§è¯­è¨€æ¨¡å‹åŠ©æ‰‹        
        """
    )
    history = []
    state = gr.State([])
    chatbot = gr.Chatbot().style(height=450)
    msg = gr.Textbox(
        label="Chat Message Box",
        placeholder="è¯·è¾“å…¥è¦æé—®çš„é—®é¢˜",
        show_label=False,
    ).style(container=False)
    
    with gr.Column():
        with gr.Row():
            submit = gr.Button("Submit")
            stop = gr.Button("Stop")
            clear = gr.Button("Clear")

    # è¾“å…¥æ¡†å›è½¦æ§½å‡½æ•°
    msg_event = msg.submit(
        fn=predict_wenxin,
        inputs=[msg, chatbot],
        outputs=[msg, chatbot],
        queue=True,
    )
    # æäº¤æŒ‰é’®æ§½å‡½æ•°
    submit_event = submit.click(
        fn=predict_wenxin,
        inputs=[msg, chatbot],
        outputs=[msg, chatbot],
        queue=True,
    )
    # åœæ­¢æŒ‰é’®æ§½å‡½æ•°
    stop.click(
        fn=None,
        inputs=None,
        outputs=None,
        cancels=[msg_event, submit_event],
        queue=False,
    )
    # æ¸…ç©ºæŒ‰é’®æ§½å‡½æ•°
    clear.click(
        fn=on_clear,
        inputs=None,
        outputs=[state, chatbot],
        queue=False,
    )

demo.queue(max_size=16,
           concurrency_count=2)
demo.launch(share=False, 
            debug=False, 
            enable_queue=True)